{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta Bank customers are leaving: little by little, chipping away every month. The bankers figured out itâ€™s cheaper to save the existing customers rather than to attract new ones. We need to predict whether a customer will leave the bank soon. I am going to build a model with the maximum possible F1 score of at least 0.59."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0     2.0       0.00              1          1               1   \n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/Churn.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " RowNumber            0\n",
      "CustomerId           0\n",
      "Surname              0\n",
      "CreditScore          0\n",
      "Geography            0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure             909\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Exited               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values:\\n\", missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Tenure after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Split the dataset into two subsets: one with missing values in \"Tenure\" and one without\n",
    "missing_tenure = df[df['Tenure'].isnull()]\n",
    "non_missing_tenure = df.dropna(subset=['Tenure'])\n",
    "\n",
    "# Separate features and target variable for the subset without missing values\n",
    "X_train = non_missing_tenure.drop(columns=['RowNumber', 'CustomerId', 'Surname', 'Tenure'])\n",
    "y_train = non_missing_tenure['Tenure']\n",
    "\n",
    "# Separate features for the subset with missing values\n",
    "X_test = missing_tenure.drop(columns=['RowNumber', 'CustomerId', 'Surname', 'Tenure'])\n",
    "\n",
    "# Perform one-hot encoding for categorical variables\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=['Geography', 'Gender'])\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=['Geography', 'Gender'])\n",
    "\n",
    "# Train a Random Forest regressor to predict the missing values in \"Tenure\"\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predict the missing values in \"Tenure\"\n",
    "predicted_tenure = rf_regressor.predict(X_test_encoded)\n",
    "\n",
    "# Fill in the missing values in the original DataFrame\n",
    "df.loc[df['Tenure'].isnull(), 'Tenure'] = predicted_tenure\n",
    "\n",
    "# Verify that there are no more missing values in \"Tenure\"\n",
    "print(\"Missing values in Tenure after imputation:\", df['Tenure'].isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore  Age  Tenure    Balance  \\\n",
      "0          1    15634602  Hargrave          619   42     2.0       0.00   \n",
      "1          2    15647311      Hill          608   41     1.0   83807.86   \n",
      "2          3    15619304      Onio          502   42     8.0  159660.80   \n",
      "3          4    15701354      Boni          699   39     1.0       0.00   \n",
      "4          5    15737888  Mitchell          850   43     2.0  125510.82   \n",
      "\n",
      "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \\\n",
      "0              1          1               1        101348.88       1   \n",
      "1              1          0               1        112542.58       0   \n",
      "2              3          1               0        113931.57       1   \n",
      "3              2          0               0         93826.63       0   \n",
      "4              1          1               1         79084.10       0   \n",
      "\n",
      "   Geography_France  Geography_Germany  Geography_Spain  Gender_Female  \\\n",
      "0                 1                  0                0              1   \n",
      "1                 0                  0                1              1   \n",
      "2                 1                  0                0              1   \n",
      "3                 1                  0                0              1   \n",
      "4                 0                  0                1              1   \n",
      "\n",
      "   Gender_Male  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n"
     ]
    }
   ],
   "source": [
    "# Perform one-hot encoding for categorical variables \"Geography\" and \"Gender\"\n",
    "df_encoded = pd.get_dummies(df, columns=['Geography', 'Gender'])\n",
    "\n",
    "# Display the first few rows of the encoded DataFrame\n",
    "print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
      "0          619   42     2.0       0.00              1          1   \n",
      "1          608   41     1.0   83807.86              1          0   \n",
      "2          502   42     8.0  159660.80              3          1   \n",
      "3          699   39     1.0       0.00              2          0   \n",
      "4          850   43     2.0  125510.82              1          1   \n",
      "\n",
      "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
      "0               1        101348.88       1                 1   \n",
      "1               1        112542.58       0                 0   \n",
      "2               0        113931.57       1                 1   \n",
      "3               0         93826.63       0                 1   \n",
      "4               1         79084.10       0                 0   \n",
      "\n",
      "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
      "0                  0                0              1            0  \n",
      "1                  0                1              1            0  \n",
      "2                  0                0              1            0  \n",
      "3                  0                0              1            0  \n",
      "4                  0                1              1            0  \n"
     ]
    }
   ],
   "source": [
    "# Drop irrelevant features such as RowNumber, CustomerId, and Surname\n",
    "df_cleaned = df_encoded.drop(columns=['RowNumber', 'CustomerId', 'Surname'])\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (10000, 13)\n",
      "Shape of y: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target variable (y)\n",
    "X = df_cleaned.drop(columns=['Exited'])\n",
    "y = df_cleaned['Exited']\n",
    "\n",
    "# Display the shape of X and y\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining the procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ensured that the data was prepared appropriately for training machine learning models. I handled missing values, encoded categorical variables, removed irrelevant features, and split the data into features and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining the balance of classes and training the model without taking into account the imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Balance:\n",
      "0    0.7963\n",
      "1    0.2037\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the proportion of customers in each class\n",
    "class_balance = df_cleaned['Exited'].value_counts(normalize=True)\n",
    "\n",
    "# Display the class balance\n",
    "print(\"Class Balance:\")\n",
    "print(class_balance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (6000, 13)\n",
      "Shape of X_val: (2000, 13)\n",
      "Shape of X_test: (2000, 13)\n",
      "Shape of y_train: (6000,)\n",
      "Shape of y_val: (2000,)\n",
      "Shape of y_test: (2000,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into 60% training, 20% validation, and 20% testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the shapes of the training, validation, and testing sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation Set: 0.801\n",
      "\n",
      "Classification Report on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      1620\n",
      "           1       0.37      0.07      0.11       380\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.59      0.52      0.50      2000\n",
      "weighted avg       0.73      0.80      0.74      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logistic_regression_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the validation set\n",
    "y_pred_val = logistic_regression_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "classification_report_val = classification_report(y_val, y_pred_val)\n",
    "\n",
    "# Display the model's performance metrics on the validation set\n",
    "print(\"Accuracy on Validation Set:\", accuracy_val)\n",
    "print(\"\\nClassification Report on Validation Set:\")\n",
    "print(classification_report_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describing the findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression model without considering class imbalance achieved an accuracy of approximately 80.05%. While the model performs well in predicting customers who haven't left the bank (class 0), with high precision, recall, and F1-score, it struggles to identify customers who have left the bank (class 1), with low recall and F1-score. This imbalance in performance indicates that the model is biased towards the majority class and fails to effectively capture the minority class. Addressing the class imbalance issue is crucial to improve the model's performance and make it more reliable for predicting customer churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the quality of the model with upsampling and downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation Set: 0.6305\n",
      "\n",
      "Classification Report on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.63      0.73      1620\n",
      "           1       0.29      0.64      0.40       380\n",
      "\n",
      "    accuracy                           0.63      2000\n",
      "   macro avg       0.58      0.63      0.57      2000\n",
      "weighted avg       0.77      0.63      0.67      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Upsample the minority class\n",
    "X_train_upsampled, y_train_upsampled = resample(X_train[y_train == 1],\n",
    "                                                y_train[y_train == 1],\n",
    "                                                replace=True,\n",
    "                                                n_samples=X_train[y_train == 0].shape[0],\n",
    "                                                random_state=42)\n",
    "\n",
    "# Combine the upsampled minority class with the majority class\n",
    "X_train_balanced = np.vstack((X_train[y_train == 0], X_train_upsampled))\n",
    "y_train_balanced = np.hstack((y_train[y_train == 0], y_train_upsampled))\n",
    "\n",
    "# Train a Logistic Regression model on the balanced training set\n",
    "logistic_regression_model = LogisticRegression(random_state=42)\n",
    "logistic_regression_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict the target variable for the validation set\n",
    "y_pred_val = logistic_regression_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "classification_report_val = classification_report(y_val, y_pred_val)\n",
    "\n",
    "# Display the model's performance metrics on the validation set\n",
    "print(\"Accuracy on Validation Set:\", accuracy_val)\n",
    "print(\"\\nClassification Report on Validation Set:\")\n",
    "print(classification_report_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Downsample the majority class\n",
    "X_train_downsampled, y_train_downsampled = resample(X_train[y_train == 0],\n",
    "                                                    y_train[y_train == 0],\n",
    "                                                    replace=False,\n",
    "                                                    n_samples=X_train[y_train == 1].shape[0],\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Combine the downsampled majority class with the minority class\n",
    "X_train_balanced = np.vstack((X_train_downsampled, X_train[y_train == 1]))\n",
    "y_train_balanced = np.hstack((y_train_downsampled, y_train[y_train == 1]))\n",
    "\n",
    "# Train a Decision Tree or Random Forest model on the balanced training set\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "random_forest_model.fit(X_train_balanced, y_train_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "{'max_depth': 18, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 112}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the parameter distributions to sample from\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 150),  # Number of trees in the forest\n",
    "    'max_depth': [None] + list(range(10, 21)),  # Maximum depth of the trees\n",
    "    'min_samples_split': randint(2, 11),  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 5)  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Initialize a Random Forest classifier\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform randomized search with 5-fold cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=random_forest, param_distributions=param_dist, n_iter=100, cv=5, scoring='f1', random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the randomized search to the balanced training set\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\")\n",
    "print(random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Validation Set:\n",
      "Logistic Regression:\n",
      "Accuracy: 0.8010\n",
      "Precision: 0.3676\n",
      "Recall: 0.0658\n",
      "F1-Score: 0.1116\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.7825\n",
      "Precision: 0.4324\n",
      "Recall: 0.4632\n",
      "F1-Score: 0.4473\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.8640\n",
      "Precision: 0.7368\n",
      "Recall: 0.4421\n",
      "F1-Score: 0.5526\n",
      "\n",
      "Based on these results, the Random Forest model has the highest F1-Score on the validation set.\n",
      "We can proceed with this model for further steps.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Random Forest', RandomForestClassifier(random_state=42))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize classifiers\n",
    "logistic_regression = LogisticRegression(random_state=42)\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train classifiers on the training set\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the validation set\n",
    "y_pred_lr = logistic_regression.predict(X_val)\n",
    "y_pred_dt = decision_tree.predict(X_val)\n",
    "y_pred_rf = random_forest.predict(X_val)\n",
    "\n",
    "# Evaluate performance of each model\n",
    "models = {\n",
    "    \"Logistic Regression\": (logistic_regression, y_pred_lr),\n",
    "    \"Decision Tree\": (decision_tree, y_pred_dt),\n",
    "    \"Random Forest\": (random_forest, y_pred_rf)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, (model, y_pred) in models.items():\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    results[name] = {\"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1-Score\": f1}\n",
    "\n",
    "# Print results\n",
    "print(\"Performance on Validation Set:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Select the model with the highest F1-score for further steps\n",
    "best_model_name = max(results, key=lambda k: results[k][\"F1-Score\"])\n",
    "best_model = models[best_model_name][0]\n",
    "\n",
    "# Prompt for continuing with the best model\n",
    "print(f\"Based on these results, the {best_model_name} model has the highest F1-Score on the validation set.\")\n",
    "print(\"We can proceed with this model for further steps.\")\n",
    "\n",
    "# Return the best model name and the best model\n",
    "best_model_name, best_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_balanced: (9546, 13)\n",
      "Shape of y_train_balanced: (9546,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Combine features and target labels\n",
    "data = np.column_stack((X_train, y_train))\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority_class = data[data[:, -1] == 0]\n",
    "minority_class = data[data[:, -1] == 1]\n",
    "\n",
    "# Get the number of samples in each class\n",
    "num_majority = len(majority_class)\n",
    "num_minority = len(minority_class)\n",
    "\n",
    "# Resample the minority class with replacement to match the size of the majority class\n",
    "minority_class_resampled = minority_class[np.random.randint(num_minority, size=num_majority)]\n",
    "\n",
    "# Combine resampled minority class with majority class\n",
    "balanced_data = np.vstack((majority_class, minority_class_resampled))\n",
    "\n",
    "# Shuffle the balanced data\n",
    "np.random.shuffle(balanced_data)\n",
    "\n",
    "# Separate features and target labels again\n",
    "X_train_balanced = balanced_data[:, :-1]\n",
    "y_train_balanced = balanced_data[:, -1]\n",
    "\n",
    "# Check the shape of the balanced training set\n",
    "print(\"Shape of X_train_balanced:\", X_train_balanced.shape)\n",
    "print(\"Shape of y_train_balanced:\", y_train_balanced.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Validation Set:\n",
      "Logistic Regression:\n",
      "Accuracy: 0.6325\n",
      "Precision: 0.2884\n",
      "Recall: 0.6368\n",
      "F1-Score: 0.3970\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.7860\n",
      "Precision: 0.4381\n",
      "Recall: 0.4474\n",
      "F1-Score: 0.4427\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.8490\n",
      "Precision: 0.6275\n",
      "Recall: 0.5053\n",
      "F1-Score: 0.5598\n",
      "\n",
      "Based on these results, the Random Forest model has the highest F1-Score on the validation set.\n",
      "We can proceed with this model for further steps.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Random Forest', RandomForestClassifier(random_state=42))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize classifiers\n",
    "logistic_regression = LogisticRegression(random_state=42)\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train classifiers on the balanced training set\n",
    "logistic_regression.fit(X_train_balanced, y_train_balanced)\n",
    "decision_tree.fit(X_train_balanced, y_train_balanced)\n",
    "random_forest.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict labels for the validation set\n",
    "y_pred_lr = logistic_regression.predict(X_val)\n",
    "y_pred_dt = decision_tree.predict(X_val)\n",
    "y_pred_rf = random_forest.predict(X_val)\n",
    "\n",
    "# Evaluate performance of each model\n",
    "models = {\n",
    "    \"Logistic Regression\": (logistic_regression, y_pred_lr),\n",
    "    \"Decision Tree\": (decision_tree, y_pred_dt),\n",
    "    \"Random Forest\": (random_forest, y_pred_rf)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, (model, y_pred) in models.items():\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    results[name] = {\"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1-Score\": f1}\n",
    "\n",
    "# Print results\n",
    "print(\"Performance on Validation Set:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Select the model with the highest F1-score for further steps\n",
    "best_model_name = max(results, key=lambda k: results[k][\"F1-Score\"])\n",
    "best_model = models[best_model_name][0]\n",
    "\n",
    "# Prompt for continuing with the best model\n",
    "print(f\"Based on these results, the {best_model_name} model has the highest F1-Score on the validation set.\")\n",
    "print(\"We can proceed with this model for further steps.\")\n",
    "\n",
    "# Return the best model name and the best model\n",
    "best_model_name, best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describing the findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on the evaluation of different models on the validation set:\n",
    "\n",
    "Logistic Regression: Achieves moderate performance with an accuracy of 62.90%. It demonstrates relatively low precision but reasonable recall, indicating it identifies a fair portion of true positives but also has a significant number of false positives.\n",
    "\n",
    "Decision Tree: Shows improved performance compared to logistic regression, with an accuracy of 79.40%. It exhibits higher precision and recall, indicating a better balance between true positives and false positives.\n",
    "\n",
    "Random Forest: Performs the best among the models evaluated, with an accuracy of 85.30%. It demonstrates the highest precision, recall, and F1-score, indicating it effectively identifies true positives while minimizing false positives.\n",
    "\n",
    "Overall, Random Forest appears to be the most promising model for predicting customer churn based on the validation set performance. It achieves the highest accuracy and provides a good balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Test Set:\n",
      "Accuracy: 0.8535\n",
      "Precision: 0.7134\n",
      "Recall: 0.5326\n",
      "F1-Score: 0.6099\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Predict labels for the test set\n",
    "y_pred_test = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test = precision_score(y_test, y_pred_test)\n",
    "recall_test = recall_score(y_test, y_pred_test)\n",
    "f1_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "# Print the evaluation metrics on the test set\n",
    "print(\"Performance on Test Set:\")\n",
    "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Precision: {precision_test:.4f}\")\n",
    "print(f\"Recall: {recall_test:.4f}\")\n",
    "print(f\"F1-Score: {f1_test:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps Performed:\n",
    "\n",
    "Data Preparation: We started by loading the dataset and performing initial data exploration. We handled missing values, encoded categorical variables, and removed irrelevant features.\n",
    "\n",
    "Class Imbalance Examination: We examined the balance of classes in the target variable \"Exited\" to understand the distribution of customers who have left versus those who haven't.\n",
    "\n",
    "Model Training without Considering Class Imbalance: We trained initial models without addressing class imbalance to establish a baseline for comparison.\n",
    "\n",
    "Improving Model Quality: We addressed class imbalance using upsampling and downsampling techniques. We trained different models (Logistic Regression, Decision Trees, and Random Forests) and selected the best-performing model based on validation set performance.\n",
    "\n",
    "Final Testing: We evaluated the selected Random Forest model on the test set and calculated the F1 score values to assess its effectiveness.\n",
    "\n",
    "Key Findings:\n",
    "\n",
    "The Random Forest model outperformed Logistic Regression and Decision Trees, achieving the highest F1 score values on the validation set.\n",
    "The final Random Forest model achieved an F1 score of 0.6099 on the test set, indicating its effectiveness in predicting customer churn.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "In conclusion, the project successfully developed a predictive model to identify customers at risk of churning. The Random Forest model demonstrated good performance in predicting customer churn, providing valuable insights that can help Beta Bank take proactive measures to retain customers and improve customer satisfaction."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 331,
    "start_time": "2024-05-16T18:53:40.854Z"
   },
   {
    "duration": 5718,
    "start_time": "2024-05-16T18:53:49.324Z"
   },
   {
    "duration": 53,
    "start_time": "2024-05-16T18:53:55.046Z"
   },
   {
    "duration": 11,
    "start_time": "2024-05-16T18:53:55.106Z"
   },
   {
    "duration": 6465,
    "start_time": "2024-05-16T18:53:55.120Z"
   },
   {
    "duration": 37,
    "start_time": "2024-05-16T18:54:01.589Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-16T18:54:01.629Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-16T18:54:01.646Z"
   },
   {
    "duration": 9,
    "start_time": "2024-05-16T18:54:01.657Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-16T18:54:09.100Z"
   },
   {
    "duration": 314,
    "start_time": "2024-05-16T18:57:07.814Z"
   },
   {
    "duration": 25,
    "start_time": "2024-05-16T18:58:51.987Z"
   },
   {
    "duration": 186,
    "start_time": "2024-05-16T19:05:27.056Z"
   },
   {
    "duration": 5,
    "start_time": "2024-05-16T19:05:34.374Z"
   },
   {
    "duration": 34,
    "start_time": "2024-05-16T19:05:34.382Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-16T19:05:34.422Z"
   },
   {
    "duration": 6285,
    "start_time": "2024-05-16T19:05:34.435Z"
   },
   {
    "duration": 20,
    "start_time": "2024-05-16T19:05:40.730Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-16T19:05:40.753Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-16T19:05:40.770Z"
   },
   {
    "duration": 46,
    "start_time": "2024-05-16T19:05:40.781Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-16T19:05:40.831Z"
   },
   {
    "duration": 300,
    "start_time": "2024-05-16T19:05:40.849Z"
   },
   {
    "duration": 18,
    "start_time": "2024-05-16T19:05:41.227Z"
   },
   {
    "duration": 184,
    "start_time": "2024-05-16T19:05:41.248Z"
   },
   {
    "duration": 0,
    "start_time": "2024-05-16T19:05:41.435Z"
   },
   {
    "duration": 470,
    "start_time": "2024-05-16T19:07:45.572Z"
   },
   {
    "duration": 171210,
    "start_time": "2024-05-16T19:07:51.525Z"
   },
   {
    "duration": 965,
    "start_time": "2024-05-16T19:17:05.612Z"
   },
   {
    "duration": 975,
    "start_time": "2024-05-16T19:19:15.798Z"
   },
   {
    "duration": 84,
    "start_time": "2024-05-16T19:23:21.374Z"
   },
   {
    "duration": 116,
    "start_time": "2024-05-16T19:24:12.400Z"
   },
   {
    "duration": 15,
    "start_time": "2024-05-16T19:30:30.274Z"
   },
   {
    "duration": 678,
    "start_time": "2024-05-16T19:33:39.864Z"
   },
   {
    "duration": 1036,
    "start_time": "2024-05-16T19:35:23.539Z"
   },
   {
    "duration": 60,
    "start_time": "2024-05-16T19:36:30.442Z"
   },
   {
    "duration": 286019,
    "start_time": "2024-05-16T19:38:27.911Z"
   },
   {
    "duration": 1363,
    "start_time": "2024-05-16T19:49:10.392Z"
   },
   {
    "duration": 319,
    "start_time": "2024-05-16T19:53:44.110Z"
   },
   {
    "duration": 1394,
    "start_time": "2024-05-16T19:54:52.078Z"
   },
   {
    "duration": 110,
    "start_time": "2024-05-16T20:03:04.031Z"
   },
   {
    "duration": 2017,
    "start_time": "2024-05-16T20:07:26.471Z"
   },
   {
    "duration": 44,
    "start_time": "2024-05-16T20:07:28.492Z"
   },
   {
    "duration": 9,
    "start_time": "2024-05-16T20:07:28.539Z"
   },
   {
    "duration": 6217,
    "start_time": "2024-05-16T20:07:28.550Z"
   },
   {
    "duration": 21,
    "start_time": "2024-05-16T20:07:34.772Z"
   },
   {
    "duration": 34,
    "start_time": "2024-05-16T20:07:34.797Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-16T20:07:34.834Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-16T20:07:34.847Z"
   },
   {
    "duration": 15,
    "start_time": "2024-05-16T20:07:34.859Z"
   },
   {
    "duration": 216,
    "start_time": "2024-05-16T20:07:34.927Z"
   },
   {
    "duration": 91,
    "start_time": "2024-05-16T20:07:35.146Z"
   },
   {
    "duration": 618,
    "start_time": "2024-05-16T20:07:35.240Z"
   },
   {
    "duration": 171377,
    "start_time": "2024-05-16T20:07:35.862Z"
   },
   {
    "duration": 1004,
    "start_time": "2024-05-16T20:10:27.244Z"
   },
   {
    "duration": 130,
    "start_time": "2024-05-16T20:10:28.251Z"
   },
   {
    "duration": 1359,
    "start_time": "2024-05-17T20:17:18.855Z"
   },
   {
    "duration": 4731,
    "start_time": "2024-05-17T20:17:25.581Z"
   },
   {
    "duration": 41,
    "start_time": "2024-05-17T20:17:30.316Z"
   },
   {
    "duration": 13,
    "start_time": "2024-05-17T20:17:30.361Z"
   },
   {
    "duration": 6223,
    "start_time": "2024-05-17T20:17:30.380Z"
   },
   {
    "duration": 21,
    "start_time": "2024-05-17T20:17:36.607Z"
   },
   {
    "duration": 15,
    "start_time": "2024-05-17T20:17:36.631Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-17T20:17:36.649Z"
   },
   {
    "duration": 9,
    "start_time": "2024-05-17T20:17:36.701Z"
   },
   {
    "duration": 17,
    "start_time": "2024-05-17T20:17:36.714Z"
   },
   {
    "duration": 267,
    "start_time": "2024-05-17T20:17:36.735Z"
   },
   {
    "duration": 452,
    "start_time": "2024-05-17T20:17:42.659Z"
   },
   {
    "duration": 1400,
    "start_time": "2024-05-17T20:26:15.326Z"
   },
   {
    "duration": 1625,
    "start_time": "2024-05-17T20:27:39.654Z"
   },
   {
    "duration": 44,
    "start_time": "2024-05-17T20:27:41.286Z"
   },
   {
    "duration": 11,
    "start_time": "2024-05-17T20:27:41.335Z"
   },
   {
    "duration": 6273,
    "start_time": "2024-05-17T20:27:41.349Z"
   },
   {
    "duration": 28,
    "start_time": "2024-05-17T20:27:47.629Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-17T20:27:47.661Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-17T20:27:47.677Z"
   },
   {
    "duration": 27,
    "start_time": "2024-05-17T20:27:47.688Z"
   },
   {
    "duration": 12,
    "start_time": "2024-05-17T20:27:47.718Z"
   },
   {
    "duration": 404,
    "start_time": "2024-05-17T20:27:47.734Z"
   },
   {
    "duration": 468,
    "start_time": "2024-05-17T20:27:48.144Z"
   },
   {
    "duration": 517,
    "start_time": "2024-05-17T20:27:48.618Z"
   },
   {
    "duration": 173973,
    "start_time": "2024-05-17T20:27:49.137Z"
   },
   {
    "duration": 1402,
    "start_time": "2024-05-17T20:30:43.118Z"
   },
   {
    "duration": 137,
    "start_time": "2024-05-17T20:30:44.523Z"
   },
   {
    "duration": 312,
    "start_time": "2024-05-18T17:59:22.365Z"
   },
   {
    "duration": 1144,
    "start_time": "2024-05-18T17:59:35.729Z"
   },
   {
    "duration": 4232,
    "start_time": "2024-05-18T17:59:46.235Z"
   },
   {
    "duration": 44,
    "start_time": "2024-05-18T17:59:50.471Z"
   },
   {
    "duration": 9,
    "start_time": "2024-05-18T17:59:50.518Z"
   },
   {
    "duration": 6071,
    "start_time": "2024-05-18T17:59:50.530Z"
   },
   {
    "duration": 18,
    "start_time": "2024-05-18T17:59:56.612Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-18T17:59:56.633Z"
   },
   {
    "duration": 7,
    "start_time": "2024-05-18T17:59:56.650Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-18T17:59:56.660Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-18T17:59:56.714Z"
   },
   {
    "duration": 205,
    "start_time": "2024-05-18T17:59:56.731Z"
   },
   {
    "duration": 319,
    "start_time": "2024-05-18T17:59:57.014Z"
   },
   {
    "duration": 519,
    "start_time": "2024-05-18T17:59:57.414Z"
   },
   {
    "duration": 163261,
    "start_time": "2024-05-18T17:59:57.935Z"
   },
   {
    "duration": 1391,
    "start_time": "2024-05-18T18:04:31.854Z"
   },
   {
    "duration": 76,
    "start_time": "2024-05-18T18:04:37.092Z"
   },
   {
    "duration": 28,
    "start_time": "2024-05-18T18:06:33.874Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-18T18:06:38.851Z"
   },
   {
    "duration": 4915,
    "start_time": "2024-05-18T18:08:12.338Z"
   },
   {
    "duration": 29,
    "start_time": "2024-05-18T18:08:29.927Z"
   },
   {
    "duration": 41,
    "start_time": "2024-05-18T18:12:15.669Z"
   },
   {
    "duration": 26,
    "start_time": "2024-05-18T18:13:13.444Z"
   },
   {
    "duration": 1816,
    "start_time": "2024-05-18T18:17:41.803Z"
   },
   {
    "duration": 63,
    "start_time": "2024-05-18T18:21:48.218Z"
   },
   {
    "duration": 1652,
    "start_time": "2024-05-18T18:28:38.507Z"
   },
   {
    "duration": 33,
    "start_time": "2024-05-18T18:28:40.162Z"
   },
   {
    "duration": 19,
    "start_time": "2024-05-18T18:28:40.198Z"
   },
   {
    "duration": 6149,
    "start_time": "2024-05-18T18:28:40.220Z"
   },
   {
    "duration": 20,
    "start_time": "2024-05-18T18:28:46.374Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-18T18:28:46.412Z"
   },
   {
    "duration": 9,
    "start_time": "2024-05-18T18:28:46.429Z"
   },
   {
    "duration": 7,
    "start_time": "2024-05-18T18:28:46.441Z"
   },
   {
    "duration": 15,
    "start_time": "2024-05-18T18:28:46.452Z"
   },
   {
    "duration": 214,
    "start_time": "2024-05-18T18:28:46.513Z"
   },
   {
    "duration": 385,
    "start_time": "2024-05-18T18:28:46.730Z"
   },
   {
    "duration": 521,
    "start_time": "2024-05-18T18:28:47.120Z"
   },
   {
    "duration": 163789,
    "start_time": "2024-05-18T18:28:47.643Z"
   },
   {
    "duration": 1309,
    "start_time": "2024-05-18T18:31:31.437Z"
   },
   {
    "duration": 27,
    "start_time": "2024-05-18T18:31:32.748Z"
   },
   {
    "duration": 1880,
    "start_time": "2024-05-18T18:31:32.778Z"
   },
   {
    "duration": 86,
    "start_time": "2024-05-18T18:31:34.661Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
